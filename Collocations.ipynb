{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collocations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjut/DPO_Materials/blob/master/Collocations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99PZCdZSv-5C",
        "colab_type": "text"
      },
      "source": [
        "#Коллокации\n",
        "Одна из задач АОТ - излвечений из коллекции текстов (из большого текста) устойчивых словосочетаний (например, 'бить баклуши' или 'бросить взгляд') или каких-то конструкций ('Торги стартовали с отметки X за баррель марки Brent' или 'Вам дать телефон X?') или имен главных героев ('Шерлок Холмс'). \n",
        "\n",
        "Будем использовать два разных набора данных\n",
        "\n",
        "(1) Возьмем три текста: часть Анны Карениной, часть Бесов, Мертвые души Гоголя. Также возьмем очень условный стоп-лист для русского языка\n",
        "\n",
        "(2) Возьмем коллекцию текстов про нанотехнологии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LEBRxY_v8YG",
        "colab_type": "code",
        "outputId": "500ff5b0-ad4d-4b01-c1e8-f4a623a652da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#загружаем файлы художественной коллекции\n",
        "#https://colab.research.google.com/\\ - загружаем тексты, которые лежат на гитхабе в папке \n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/anna_karenina_part.txt\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/besy_dostoevsky_part.txt\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/avidreaders.ru__mertvye-dushi.txt"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1350k  100 1350k    0     0  5233k      0 --:--:-- --:--:-- --:--:-- 5233k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1206k  100 1206k    0     0  2594k      0 --:--:-- --:--:-- --:--:-- 2588k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1342k  100 1342k    0     0  5993k      0 --:--:-- --:--:-- --:--:-- 5993k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBJWG5Lo7jaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#создаем список файлов с указанием кодировки (чтобы в дальнейшем не писать вызов функции отдельно, а вызывать функции в цикле)\n",
        "files = [\"anna_karenina_part.txt\", \"besy_dostoevsky_part.txt\", \"avidreaders.ru__mertvye-dushi.txt\"]\n",
        "enc = \"utf-8\"\n",
        "n_files = len(files)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUHyT20x9UFF",
        "colab_type": "code",
        "outputId": "d9ecd51a-aa9a-4197-ec6c-450ca273595e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#считываем содержимое файлов; \"texts\" - список, элемнты списка - тексты, которые содержатся в наших файлах\n",
        "texts = [open(fname, encoding = enc).read() for fname in files]\n",
        "#смотрим, что записалось в первые 100 символов нулевого элемента списка\n",
        "texts[0][:100]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Annotation\\n\\n\\n«Анна Каренина» – это сложное, психологически утонченное, остропроблемное произведение,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N7bS8RI-5Hf",
        "colab_type": "code",
        "outputId": "e41b3cd7-348f-4533-e1b9-d6f48821903c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#смотрим длину текстов; перебираем по числу элементов списка \"texts\"\n",
        "for i in range(n_files):\n",
        "  print(f\"Длина {files[i]:40} - {len(texts[i]):10} символов\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Длина anna_karenina_part.txt                   -     769151 символов\n",
            "Длина besy_dostoevsky_part.txt                 -     683391 символов\n",
            "Длина avidreaders.ru__mertvye-dushi.txt        -     762191 символов\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McH3cYO1rcCM",
        "colab_type": "code",
        "outputId": "8db40d68-e5be-4ed3-dac9-57f1302b1087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from string import punctuation\n",
        "import numpy as np\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/stoplist_ru.txt\n",
        "stoplist_ru = set(open(\"stoplist_ru.txt\", mode = 'r', encoding = \"utf-8\").read().split())\n",
        "print(stoplist_ru)\n",
        "\n",
        "def tokenize(text, del_stop = False):\n",
        "    tokenized_text = [word.strip(punctuation) for word in text.lower().split()]\n",
        "                                                            \n",
        "    tokenized_text = [word for word in tokenized_text if word]\n",
        "    if del_stop:\n",
        "      tokenized_text = [word for word in tokenized_text if word not in stoplist_ru]\n",
        "    return tokenized_text\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    76  100    76    0     0    410      0 --:--:-- --:--:-- --:--:--   413\n",
            "{'был', 'с', '-', '–', 'была', 'было', 'были', 'то', 'же', 'в', 'и', 'а', 'на', '—', 'не'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vOOMVkyEjMM",
        "colab_type": "text"
      },
      "source": [
        "Сравним тексты по словам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXTIsOc8Ehvc",
        "colab_type": "code",
        "outputId": "0c67d7fb-6115-41b9-c30f-5f4296619297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "stop = True\n",
        "norm_texts = [tokenize(text, stop) for text in texts]\n",
        "print(norm_texts[0][100:110])\n",
        "#смотрим длину текстов в токенах\n",
        "for i in range(n_files):\n",
        "  print(f\"Длина {files[i]:40} - {len(norm_texts[i]):10} токенов; {len(set(norm_texts[i]))} уникальных словоформ\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['все', 'смешалось', 'доме', 'облонских', 'жена', 'узнала', 'что', 'муж', 'связи', 'бывшею']\n",
            "Длина anna_karenina_part.txt                   -     103424 токенов; 21101 уникальных словоформ\n",
            "Длина besy_dostoevsky_part.txt                 -      90743 токенов; 20995 уникальных словоформ\n",
            "Длина avidreaders.ru__mertvye-dushi.txt        -      99424 токенов; 25889 уникальных словоформ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbMJWpNHe2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkMD3nciI30M",
        "colab_type": "code",
        "outputId": "73855823-b10d-4a5b-8897-fe1d82a629cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "vocabs = [Counter(norm_text) for norm_text in norm_texts]\n",
        "most_commons = [vocab.most_common(20) for vocab in vocabs]\n",
        "\n",
        "joint_most_common = {}\n",
        "for mc in most_commons:\n",
        "  for i in mc:\n",
        "    joint_most_common[i[0]] = [0,0,0]\n",
        "\n",
        "for k in joint_most_common:\n",
        "  for i in range(n_files):\n",
        "    joint_most_common[k][i] = vocabs[i].get(k, 0)\n",
        "  print(f'{k:15} {joint_most_common[k]}')\n",
        "\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "что             [2620, 1816, 1982]\n",
            "он              [2317, 1224, 1341]\n",
            "она             [1537, 562, 138]\n",
            "я               [1392, 1772, 760]\n",
            "как             [1201, 808, 1225]\n",
            "но              [1158, 959, 621]\n",
            "его             [1088, 653, 733]\n",
            "это             [1003, 707, 616]\n",
            "к               [875, 583, 571]\n",
            "ее              [834, 341, 177]\n",
            "все             [750, 236, 691]\n",
            "так             [610, 588, 727]\n",
            "сказал          [581, 41, 493]\n",
            "ему             [539, 214, 351]\n",
            "за              [523, 433, 489]\n",
            "о               [513, 464, 262]\n",
            "только          [477, 408, 450]\n",
            "левин           [476, 0, 0]\n",
            "ты              [444, 162, 323]\n",
            "у               [417, 487, 583]\n",
            "вы              [379, 900, 310]\n",
            "всё             [0, 509, 63]\n",
            "бы              [369, 468, 658]\n",
            "по              [379, 456, 544]\n",
            "мне             [291, 397, 232]\n",
            "еще             [284, 383, 350]\n",
            "чичиков         [0, 0, 602]\n",
            "да              [353, 329, 565]\n",
            "из              [329, 330, 433]\n",
            "уже             [234, 299, 412]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUJu6xUxphnd",
        "colab_type": "code",
        "outputId": "0bd940b4-2eff-4e1b-a8e0-c5fea0492c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "# устанавливаем pymorphy и импортируем необходимые модули\n",
        "!pip install pymorphy2[fast]\n",
        "import itertools\n",
        "import nltk\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "morph = MorphAnalyzer()\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
            "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.8)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-b5688c94c27c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(stopwords.words('russian'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mstops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'bool' and 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CruEgjAr4Dys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b017d43-ddc6-426d-ae13-0c0e2cb75c28"
      },
      "source": [
        " print(punctuation)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoLSTRtI1fqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1f82f72d-1700-4a2f-8785-45a40bf1fab1"
      },
      "source": [
        "#сформируем список стопслов, тут можно сделать свой собственный файл стопслов и добавить его\n",
        "print(stoplist_ru)\n",
        "stops =  stoplist_ru.union(stopwords.words('russian'))\n",
        "print(stops)\n",
        "print(stops.intersection(stoplist_ru))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'был', 'с', '-', '–', 'была', 'было', 'были', 'то', 'же', 'в', 'и', 'а', 'на', '—', 'не'}\n",
            "{'теперь', 'может', 'тоже', 'какой', 'много', 'два', 'он', 'тут', 'между', 'зачем', 'себе', 'хорошо', 'чем', 'один', 'во', 'даже', 'себя', 'они', 'надо', 'всех', 'три', 'уж', 'был', 'ним', 'над', 'их', 'или', 'все', 'совсем', 'если', 'ну', 'там', 'ведь', 'чтоб', 'у', 'при', 'хоть', 'к', 'ты', 'меня', 'ли', 'нет', 'здесь', 'ее', 'можно', 'для', 'была', 'ж', 'то', 'эти', '—', 'никогда', 'разве', 'эту', 'со', 'сам', 'тебя', 'под', '–', 'есть', 'было', 'по', 'моя', 'быть', 'за', 'нибудь', 'в', 'на', 'только', 'из', 'но', 'чуть', 'лучше', 'где', 'будет', 'этой', 'им', 'иногда', 'куда', 'вот', 'ему', 'с', 'без', 'как', 'его', 'потом', 'этого', 'такой', 'чего', 'до', 'что', 'я', 'после', 'раз', 'уже', 'нельзя', 'потому', 'вдруг', 'другой', 'тогда', 'ней', 'и', 'когда', 'впрочем', 'о', 'от', 'того', 'наконец', 'него', 'кто', 'через', 'этом', 'еще', 'мой', 'этот', 'она', 'сейчас', 'всего', 'чтобы', 'об', 'опять', 'про', 'вас', 'не', 'мне', 'свою', 'ни', 'нее', 'тем', 'а', 'всегда', 'вы', 'нас', 'тот', 'мы', 'будто', 'всю', 'вам', 'более', 'ей', 'какая', 'конечно', 'же', 'почти', 'перед', '-', 'больше', 'были', 'так', 'ничего', 'них', 'том', 'да', 'бы'}\n",
            "{'был', 'с', '–', '-', 'была', 'было', 'были', 'то', 'же', 'в', 'и', 'а', 'на', '—', 'не'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvaqyaqjHUOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#функция для токенизации и нормализации текста\n",
        "def normalize(text):\n",
        "    punct = punctuation +\"«»\"\n",
        "    normalized_text = [morph.parse(word.strip(punct))[0].normal_form for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word and word not in stops]\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggxFwPBErcDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_66pcuyyr_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b57bff5-d2b7-4b4a-c544-48732a109f1d"
      },
      "source": [
        "#лемматизируем тексты\n",
        "lemm_texts = [normalize(text) for text in texts]\n",
        "print(lemm_texts[2][:20])"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['annotation', 'мёртвый', 'душа', 'уникальный', 'роман', 'стать', 'русский', 'литература', 'своеобразный', 'эталон', 'иронический', 'проза', 'книга', 'раздёргать', 'цитата', 'ещё', 'xix', 'no-прежний', 'потрясать', 'воображение']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3kJoYpi6xT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "8024a49f-3d62-494a-e288-2a1de69fcea3"
      },
      "source": [
        "word_counter = Counter()\n",
        "\n",
        "for text in lemm_texts:\n",
        "    word_counter.update(ngrammer(text, n=2))\n",
        "\n",
        "word_counter.most_common(30)\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('степан трофим', 331),\n",
              " ('варвар пётр', 288),\n",
              " ('николай всеволод', 288),\n",
              " ('весь это', 227),\n",
              " ('алексей александр', 218),\n",
              " ('степан аркадьй', 205),\n",
              " ('пётр степан', 134),\n",
              " ('сказать чичиков', 129),\n",
              " ('крайний мера', 102),\n",
              " ('павел иван', 97),\n",
              " ('самый дело', 91),\n",
              " ('это весь', 87),\n",
              " ('маврикий николай', 85),\n",
              " ('человек который', 84),\n",
              " ('сергей иван', 82),\n",
              " ('весь равно', 82),\n",
              " ('это время', 80),\n",
              " ('варвара пётр', 77),\n",
              " ('знать это', 75),\n",
              " ('говорить это', 75),\n",
              " ('дарья александр', 74),\n",
              " ('это дело', 69),\n",
              " ('друг друг', 67),\n",
              " ('сказать левин', 67),\n",
              " ('сказать это', 66),\n",
              " ('молодая человек', 60),\n",
              " ('лизавета николай', 56),\n",
              " ('сей пора', 55),\n",
              " ('весь ещё', 54),\n",
              " ('весь жизнь', 54)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSV49eZ0716G",
        "colab_type": "text"
      },
      "source": [
        "В списке есть коллокации, которые попали в список из-за того, что одно слово очень частотное и вообще встречается много в каких контекстах. Нас скорее интересуют случаи, когда слова в большинстве случаев встречаются вместе. Для этого мы можем придумать какие-нибудь формулы, учитывающие частоты слов по отдельности и общую частоту.\n",
        "\n",
        "Самый простой способ - взять количество упоминаний биграма и поделить на сумму количеств упоминаний слов по отдельности.\n",
        "Можно вычислить коэффициент Дайса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC2CatmK8Dna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scorer_simple(word_count_a, word_count_b, bigram_count, *args):\n",
        "    try:\n",
        "        score = bigram_count/((word_count_a+word_count_b))\n",
        "    \n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQwZ55Ds8phg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Сделаем функцию, которая будет делать счетчики для слов и биграммов.\n",
        "def collect_stats(texts):\n",
        "    ## соберем статистики для отдельных слов\n",
        "    ## и биграммов\n",
        "    \n",
        "    unigrams = Counter()\n",
        "    bigrams = Counter()\n",
        "    \n",
        "    for text in texts:\n",
        "        unigrams.update(text)\n",
        "        bigrams.update(ngrammer(text, 2))\n",
        "    \n",
        "    return unigrams, bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkzXt4cw83qY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "2455e74a-8642-4c9f-aaaf-c8fa47cb1026"
      },
      "source": [
        "unigrams, bigrams = collect_stats(lemm_texts)\n",
        "unigrams.most_common(50)\n",
        "bigrams.most_common(50)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-230-e70eda632397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemm_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-201-5bcfc4666317>\u001b[0m in \u001b[0;36mcollect_stats\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0munigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrammer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Qn8DeB_6mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_bigrams(unigrams, bigrams, scorer, threshold=-100000, min_count=5):\n",
        "    ## посчитаем метрику для каждого нграмма\n",
        "    bigram2score = Counter()\n",
        "    len_vocab = len(unigrams)\n",
        "    for bigram in bigrams:\n",
        "        score = scorer(unigrams[bigram[0]], unigrams[bigram[1]], \n",
        "                       bigrams[bigram], len_vocab, min_count)\n",
        "        \n",
        "        ## если метрика выше порога, добавляем в словарик\n",
        "        if score > threshold:\n",
        "            bigram2score[bigram] = score\n",
        "    \n",
        "    return bigram2score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN3x5dUX_QVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ca3c293f-ce0e-4d00-e0be-6facbc2b478a"
      },
      "source": [
        "bigram2score = score_bigrams(unigrams, bigrams, scorer_simple)\n",
        "bigram2score.most_common(20)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('весь это', 113.5),\n",
              " ('крайний мера', 51.0),\n",
              " ('человек который', 42.0),\n",
              " ('сергей иван', 41.0),\n",
              " ('весь равно', 41.0),\n",
              " ('друг друг', 33.5),\n",
              " ('сей пора', 27.5),\n",
              " ('весь ещё', 27.0),\n",
              " ('весь жизнь', 27.0),\n",
              " ('весь свой', 25.5),\n",
              " ('прасковья иван', 24.0),\n",
              " ('весь весь', 20.5),\n",
              " ('черта знать', 20.5),\n",
              " ('весь сторона', 18.5),\n",
              " ('петра степан', 18.0),\n",
              " ('весь время', 17.0),\n",
              " ('семён яков', 17.0),\n",
              " ('весь город', 15.5),\n",
              " ('весь знать', 14.5),\n",
              " ('герой наш', 14.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgMZOL1TAjn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.collocations import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvCv97LBAoLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ib5SybzAsIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "0945a7a6-12ad-4330-9622-4b289cf8d6a9"
      },
      "source": [
        "all_texts_lemm = []\n",
        "for t in lemm_texts:\n",
        "  all_texts_lemm += t\n",
        "finder2 = BigramCollocationFinder.from_words(all_texts_lemm)\n",
        "finder2.nbest(bigram_measures.likelihood_ratio, 50)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('степан', 'трофим'),\n",
              " ('николай', 'всеволод'),\n",
              " ('варвар', 'пётр'),\n",
              " ('алексей', 'александр'),\n",
              " ('степан', 'аркадьй'),\n",
              " ('крайний', 'мера'),\n",
              " ('павел', 'иван'),\n",
              " ('сергей', 'иван'),\n",
              " ('маврикий', 'николай'),\n",
              " ('пётр', 'степан'),\n",
              " ('варвара', 'пётр'),\n",
              " ('дарья', 'александр'),\n",
              " ('юлий', 'михайло'),\n",
              " ('фон', 'лембка'),\n",
              " ('сей', 'пора'),\n",
              " ('марья', 'тимофей'),\n",
              " ('лизавета', 'николай'),\n",
              " ('весь', 'равно'),\n",
              " ('мёртвый', 'душа'),\n",
              " ('семён', 'яков'),\n",
              " ('друг', 'друг'),\n",
              " ('прасковья', 'иван'),\n",
              " ('ваш', 'превосходительство'),\n",
              " ('афанасий', 'василий'),\n",
              " ('сказать', 'чичиков'),\n",
              " ('андрей', 'антоно'),\n",
              " ('юлия', 'михайло'),\n",
              " ('мадам', 'шталь'),\n",
              " ('самый', 'дело'),\n",
              " ('молодая', 'человек'),\n",
              " ('дарья', 'павло'),\n",
              " ('агафья', 'михайло'),\n",
              " ('ха', 'ха'),\n",
              " ('ваш', 'сиятельство'),\n",
              " ('полковой', 'командир'),\n",
              " ('петра', 'степан'),\n",
              " ('графиня', 'лидий'),\n",
              " ('алексей', 'нилыч'),\n",
              " ('константин', 'левин'),\n",
              " ('константин', 'дмитрич'),\n",
              " ('андрей', 'иван'),\n",
              " ('матрена', 'филимон'),\n",
              " ('весь', 'это'),\n",
              " ('выражение', 'лицо'),\n",
              " ('лидий', 'иван'),\n",
              " ('н.в', 'гоголь'),\n",
              " ('двадцать', 'год'),\n",
              " ('мочь', 'представить'),\n",
              " ('черта', 'знать'),\n",
              " ('герой', 'наш')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    }
  ]
}