{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "hi_ngrams.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CBypkkcrcB2",
        "colab_type": "text"
      },
      "source": [
        "## Языковое моделирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo7tm8KgrcB4",
        "colab_type": "text"
      },
      "source": [
        "Языковое моделирование заключается в приписывании вероятности последовательности слов. Сейчас языковые модели используются практически во всех nlp задачах. Всякие Берты и Элмо - языковые модели. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYkwgolKrcB6",
        "colab_type": "text"
      },
      "source": [
        "Это достаточно сложная тема, поэтому будем разбирать постепенно. Сегодня разберём самые основы. Научимся приписывать вероятность последовательности слов и попробуем генерировать текст."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeOWfJjOrcB8",
        "colab_type": "text"
      },
      "source": [
        "Возьмем два текста: Анну Каренину и Бесов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlNHe6uyrsPy",
        "colab_type": "code",
        "outputId": "82197f65-87c5-4ad6-a773-90f1a01bb689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#https://colab.research.google.com/\\\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/anna_karenina_part.txt\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/besy_dostoevsky_part.txt\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/avidreaders.ru__mertvye-dushi.txt\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/sjut/DPO_Materials/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/stoplist_ru.txt"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1350k  100 1350k    0     0  3184k      0 --:--:-- --:--:-- --:--:-- 3184k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1206k  100 1206k    0     0  2949k      0 --:--:-- --:--:-- --:--:-- 2949k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1342k  100 1342k    0     0  1330k      0  0:00:01  0:00:01 --:--:-- 1330k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    91  100    91    0     0    486      0 --:--:-- --:--:-- --:--:--   486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8duVLUBrcB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(file1, enc1) = (\"anna_karenina_part.txt\", \"utf-8\")\n",
        "(file2, enc2) = (\"besy_dostoevsky_part.txt\", \"utf-8\")\n",
        "(file3, enc3) = (\"avidreaders.ru__mertvye-dushi.txt\", \"utf-8\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvUIe5MLqI52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = open(file1, encoding = enc1).read()\n",
        "text2 = open(file2, encoding = enc2).read()\n",
        "text3 = open(file3, encoding = enc3).read()\n",
        "#print(text1[:20])\n",
        "# print(text2[:20])\n",
        "# print(text3[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMGhXX6PrcCE",
        "colab_type": "text"
      },
      "source": [
        "Анна Каренина немного больше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EpkuilprcCF",
        "colab_type": "code",
        "outputId": "e2a896c9-de4b-4325-a8d2-a13e44c0c122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Длина {file1} - \", len(text1))\n",
        "print(f\"Длина {file2} - \", len(text2))\n",
        "print(f\"Длина {file3} - \", len(text3))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Длина anna_karenina_part.txt -  769151\n",
            "Длина besy_dostoevsky_part.txt -  683391\n",
            "Длина avidreaders.ru__mertvye-dushi.txt -  762191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJcqDFFvrcCL",
        "colab_type": "text"
      },
      "source": [
        "Напишем простую функцию для нормализации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6faWWdCBro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "db6c9143-d820-4cd5-9b3a-e9f7ef76d2a9"
      },
      "source": [
        "\n",
        "stoplist_ru = set(open(\"stoplist_ru.txt\", mode = 'r', encoding = \"utf-8\").read().split())\n",
        "stoplist_ru\n",
        "#len(stoplist_ru)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'а',\n",
              " 'был',\n",
              " 'была',\n",
              " 'были',\n",
              " 'в',\n",
              " 'его',\n",
              " 'ее',\n",
              " 'и',\n",
              " 'их',\n",
              " 'не',\n",
              " 'он',\n",
              " 'она',\n",
              " 'они',\n",
              " 'тот',\n",
              " 'этот'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McH3cYO1rcCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "import numpy as np\n",
        "\n",
        "def normalize(text, del_stop = False):\n",
        "    normalized_text = [word.strip(punctuation) for word in text.lower().split()]\n",
        "                                                            \n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    if del_stop:\n",
        "      normalized_text = [word for word in normalized_text if word not in stoplist_ru]\n",
        "    return normalized_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FO1baixrcCQ",
        "colab_type": "text"
      },
      "source": [
        "Сравним тексты по словам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6_JKN7rcCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = False\n",
        "norm_text1 = normalize(text1, stop)\n",
        "norm_text2 = normalize(text2, stop)\n",
        "norm_text3 = normalize(text3, stop)\n",
        "#del text1, text2, text3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvMvbhKHrcCU",
        "colab_type": "code",
        "outputId": "6ef52e9d-b599-4ece-d5c6-f4d8db3e2573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Длина {file1} - {len(norm_text1)} токенов\" )\n",
        "print(f\"Длина {file2} - {len(norm_text2)} токенов\" )\n",
        "print(f\"Длина {file3} - {len(norm_text3)} токенов\" )"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Длина anna_karenina_part.txt - 126487 токенов\n",
            "Длина besy_dostoevsky_part.txt - 109620 токенов\n",
            "Длина avidreaders.ru__mertvye-dushi.txt - 119962 токенов\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F34U1pgzrcCX",
        "colab_type": "text"
      },
      "source": [
        "\"Мертвые души\" короче фрагмента из \"Анны Карениной\", но уникальных слов там больше!\n",
        "Бесы короче примерно на 17 тыс. токенов, а уникальных слов всего на 1 тыс. меньше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRfv2mS1rcCY",
        "colab_type": "code",
        "outputId": "440c5aed-ab38-4ed4-b408-ab1c7f38b6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Уникальных словоформ в {file1} - {len(set(norm_text1))}\")\n",
        "print(f\"Уникальный словоформ в {file2} - {len(set(norm_text2))}\")\n",
        "print(f\"Уникальных словоформ в {file3} - {len(set(norm_text3))}\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Уникальных словоформ в anna_karenina_part.txt - 21114\n",
            "Уникальный словоформ в besy_dostoevsky_part.txt - 21009\n",
            "Уникальных словоформ в avidreaders.ru__mertvye-dushi.txt - 25903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V4fvE0QrcCb",
        "colab_type": "text"
      },
      "source": [
        "Посчитаем, сколько раз встречаются слова и выведем самые частотные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdLOPTkFrcCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdxBDHSXrcCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_text1 = Counter(norm_text1)\n",
        "vocab_text2 = Counter(norm_text2)\n",
        "vocab_text3 = Counter(norm_text3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiKHyVSGrcCh",
        "colab_type": "code",
        "outputId": "988a8a94-0584-4958-905b-8fd8b789282c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "vocab_text1.most_common(10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 5851),\n",
              " ('–', 5221),\n",
              " ('не', 2908),\n",
              " ('что', 2620),\n",
              " ('в', 2498),\n",
              " ('он', 2317),\n",
              " ('на', 1624),\n",
              " ('она', 1537),\n",
              " ('с', 1506),\n",
              " ('я', 1392)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NNTIDjYrcCk",
        "colab_type": "code",
        "outputId": "23aceca4-0b9d-445a-a97c-efb66b0b219c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "vocab_text2.most_common(10)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 4551),\n",
              " ('—', 3649),\n",
              " ('в', 2549),\n",
              " ('не', 2425),\n",
              " ('что', 1816),\n",
              " ('я', 1772),\n",
              " ('с', 1342),\n",
              " ('на', 1227),\n",
              " ('он', 1224),\n",
              " ('но', 959)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n57MW7LlIZ4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dae0c20f-e958-4b8a-c164-c2d576117036"
      },
      "source": [
        "vocab_text3.most_common(10)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 4851),\n",
              " ('–', 3788),\n",
              " ('в', 2960),\n",
              " ('не', 2447),\n",
              " ('что', 1982),\n",
              " ('на', 1734),\n",
              " ('он', 1341),\n",
              " ('с', 1283),\n",
              " ('как', 1225),\n",
              " ('а', 888)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vC7LFFuxbD",
        "colab_type": "text"
      },
      "source": [
        "-------------------------------------------------------------\n",
        "*Небольшая вставка - что такое Python Counter:\n",
        "\n",
        "A Counter is a container that keeps track of how many times equivalent values are added. It can be used to implement the same algorithms for which bag or multiset data structures are commonly used in other languages.\n",
        "\n",
        "Initializing\n",
        "Counter supports three forms of initialization. Its constructor can be called with a sequence of items, a dictionary containing keys and counts, or using keyword arguments mapping string names to counts.\n",
        "\n",
        "\n",
        "https://pymotw.com/2/collections/counter.html <br>\n",
        "https://pythonworld.ru/moduli/modul-collections.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW19TpRovQAi",
        "colab_type": "code",
        "outputId": "66ebe141-0797-4c52-b596-6a4d43064d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import collections\n",
        "\n",
        "print(collections.Counter(['a', 'b', 'c', 'a', 'b', 'b']))\n",
        "print(collections.Counter({'a':2, 'b':3, 'c':1}))\n",
        "print(collections.Counter(a=2, b=3, c=1))\n",
        "#The results of all three forms of initialization are the same."
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'b': 3, 'a': 2, 'c': 1})\n",
            "Counter({'b': 3, 'a': 2, 'c': 1})\n",
            "Counter({'b': 3, 'a': 2, 'c': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SRxlGx0vteo",
        "colab_type": "text"
      },
      "source": [
        "Сравнивать употребимость конкретных слов в разных текстах в абсолютных числах неудобно. Нормализуем счётчики на размеры текстов. Так у нас получается вероятность слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hdr3haMrcCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def probas_vocab(vocab):\n",
        "  len_text = len(vocab)\n",
        "  probas_text = Counter({word : c / len_text for word, c in vocab.items()})\n",
        "  return probas_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf1xR1kcLDl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e65f6fef-a080-4e4a-982a-7e9af6c08bed"
      },
      "source": [
        "probas_text1 = probas_vocab(vocab_text1)\n",
        "print(f\"{file1}\\n\"+\"\\n\".join(str(x) for x in probas_text1.most_common(20)))\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anna_karenina_part.txt\n",
            "('и', 0.2771147106185469)\n",
            "('–', 0.24727668845315903)\n",
            "('не', 0.13772852136023492)\n",
            "('что', 0.12408828265605759)\n",
            "('в', 0.11831012598276025)\n",
            "('он', 0.10973761485270436)\n",
            "('на', 0.07691579047077768)\n",
            "('она', 0.07279530169555745)\n",
            "('с', 0.07132708155726059)\n",
            "('я', 0.06592782040352373)\n",
            "('как', 0.05688168987401724)\n",
            "('но', 0.05484512645637965)\n",
            "('его', 0.05152979066022544)\n",
            "('это', 0.04750402576489533)\n",
            "('к', 0.041441697451927634)\n",
            "('ее', 0.03949985791418016)\n",
            "('все', 0.035521454958795114)\n",
            "('было', 0.032821824381926684)\n",
            "('а', 0.029317040825992232)\n",
            "('так', 0.02889078336648669)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Akz7gM4rcCr",
        "colab_type": "code",
        "outputId": "f658953a-d183-4f47-8c6a-5ac9e0de49dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "probas_text2 = Counter({word:c/len(norm_text2) for word, c in vocab_text2.items()})\n",
        "probas_text2.most_common(20)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 0.04151614668856048),\n",
              " ('—', 0.0332877212187557),\n",
              " ('в', 0.023253056011676702),\n",
              " ('не', 0.022121875570151432),\n",
              " ('что', 0.016566320014595876),\n",
              " ('я', 0.016164933406312715),\n",
              " ('с', 0.01224229155263638),\n",
              " ('на', 0.011193212917350849),\n",
              " ('он', 0.01116584564860427),\n",
              " ('но', 0.008748403575989784),\n",
              " ('вы', 0.008210180623973728),\n",
              " ('а', 0.0082010582010582),\n",
              " ('как', 0.007370917715745302),\n",
              " ('же', 0.006814449917898193),\n",
              " ('это', 0.006449553001277139),\n",
              " ('его', 0.005956942163838716),\n",
              " ('так', 0.0053639846743295016),\n",
              " ('к', 0.00531837255975187),\n",
              " ('она', 0.0051268016785258165),\n",
              " ('всё', 0.004643313264002919)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFlnx2xQD4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "61302d4c-1f6a-4829-ee8a-1ed61e83c5d2"
      },
      "source": [
        "probas_text3 = probas_vocab(vocab_text3)\n",
        "print(f\"{file3}\\n\"+\"\\n\".join(str(x) for x in probas_text3.most_common(20)))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avidreaders.ru__mertvye-dushi.txt\n",
            "('и', 0.18727560514226152)\n",
            "('–', 0.146237887503378)\n",
            "('в', 0.11427247809134077)\n",
            "('не', 0.09446782225996989)\n",
            "('что', 0.07651623364089101)\n",
            "('на', 0.06694205304404895)\n",
            "('он', 0.051770065243408096)\n",
            "('с', 0.04953094236188858)\n",
            "('как', 0.04729181948036907)\n",
            "('а', 0.03428174342740223)\n",
            "('я', 0.029340230861290197)\n",
            "('его', 0.028297880554375942)\n",
            "('так', 0.028066247152839438)\n",
            "('все', 0.02667644674362043)\n",
            "('бы', 0.025402463035169673)\n",
            "('же', 0.02536385746824692)\n",
            "('было', 0.024205690460564415)\n",
            "('но', 0.02397405705902791)\n",
            "('это', 0.02378102922441416)\n",
            "('чичиков', 0.023240551287495657)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6CIfQckrcCu",
        "colab_type": "text"
      },
      "source": [
        "Эти вероятности уже можно использовать, чтобы ответить на вопрос - кто из авторов сказал бы такую фразу?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TVTaX2KrcCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fafdabc6-ad41-4161-894e-69b8a0191096"
      },
      "source": [
        "phrase = 'Жена узнала, что муж был в связи'\n",
        "\n",
        "prob = Counter({'tolstoy':0, 'dostoevsky':0, 'gogol':0})\n",
        "prob_raw = Counter({'tolstoy':1, 'dostoevsky':1, 'gogol':1})\n",
        "\n",
        "for word in normalize(phrase):\n",
        "    prob['tolstoy'] += np.log(probas_text1.get(word, 0.00001))\n",
        "    prob['dostoevsky'] += np.log(probas_text2.get(word, 0.00001))\n",
        "    prob['gogol'] += np.log(probas_text3.get(word, 0.00001))\n",
        "    prob_raw['tolstoy'] *= probas_text1.get(word, 0.00001)\n",
        "    prob_raw['dostoevsky'] *= probas_text2.get(word, 0.00001)\n",
        "    prob_raw['gogol'] *= probas_text3.get(word, 0.00001)\n",
        "    print(f\"{probas_text1.get(word, 0.00001):.10f}  {probas_text2.get(word, 0.00001):.10f}  {probas_text3.get(word, 0.00001):.10f} {word}\")\n",
        "\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0023680970  0.0000821018  0.0006176891 жена\n",
            "0.0008998769  0.0000821018  0.0000386056 узнала\n",
            "0.1240882827  0.0165663200  0.0765162336 что\n",
            "0.0018471157  0.0000456121  0.0002702390 муж\n",
            "0.0184711566  0.0029556650  0.0166776049 был\n",
            "0.1183101260  0.0232530560  0.1142724781 в\n",
            "0.0008525149  0.0001185915  0.0000386056 связи\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgmNJ5YDwASd",
        "colab_type": "text"
      },
      "source": [
        "-------\n",
        "небольшая вставка про  https://www.geeksforgeeks.org/numpy-log-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-arhk_vnrcCy",
        "colab_type": "code",
        "outputId": "4e4a0a2d-a11a-48b2-9cac-fb59738824be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(prob.most_common())\n",
        "prob_raw.most_common()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('tolstoy', -34.633123830662726), ('gogol', -44.76306777592244), ('dostoevsky', -51.53599792630299)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tolstoy', 9.099665523991813e-16),\n",
              " ('gogol', 3.62782786167172e-20),\n",
              " ('dostoevsky', 4.151456400512162e-23)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV5rSufCrcC1",
        "colab_type": "text"
      },
      "source": [
        "Результаты получаются не очень точные. Возможно это из-за того, что мы считаем слова незовисымыми друг от друга. А это очевидно не так"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUdwdseGrcC2",
        "colab_type": "text"
      },
      "source": [
        "По-хорошему вероятность последовательности нужно расчитывать по формуле полной вероятности. Но у нас не очень большие тексты и мы не можем получить вероятности для длинных фраз (их просто может не быть в текстах). Поэтому мы воспользуемся предположением Маркова и будем учитывать только предыдущее слово."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msfd21-nrcC3",
        "colab_type": "text"
      },
      "source": [
        "Чтобы расчитать вероятность с таким предположением, нам достаточно найти количество вхождений для каждого биграмма."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjKyn84rcC4",
        "colab_type": "code",
        "outputId": "858a500f-f6b7-4156-c05e-e3fa409673bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPBVMrnjrcC7",
        "colab_type": "text"
      },
      "source": [
        "Для того, чтобы у нас получились честные вероятности и можно было посчитать вероятность первого слова, нам нужно добавить тэг маркирующий начало предложений \\< start \\>\n",
        "\n",
        "Дальше мы попробуем сгенерировать текст, используя эти вероятности, и нам нужно будет когда-то остановится. Для этого добавим тэг окончания \\< end \\>\n",
        "\n",
        "Ну и поделим все на предложения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_QWIsbrcC7",
        "colab_type": "code",
        "outputId": "29fa527f-a780-4137-ff69-2eaccc671ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentences_text2 = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(text2)]\n",
        "sentences_text1 = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(text1)]\n",
        "sentences_text3 = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(text3)]\n",
        "print(f\"количество предложений в {file1} - {len(sentences_text1)}\")\n",
        "print(f\"количество предложений в {file2} - {len(sentences_text2)}\")\n",
        "print(f\"количество предложений в {file3} - {len(sentences_text3)}\")\n",
        "sentences_text1 = sentences_text1[:3000]\n",
        "sentences_text2 = sentences_text2[:3000]\n",
        "sentences_text2 = sentences_text2[:3000]"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "количество предложений в anna_karenina_part.txt - 8915\n",
            "количество предложений в besy_dostoevsky_part.txt - 7634\n",
            "количество предложений в avidreaders.ru__mertvye-dushi.txt - 7576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyX9MyecoO3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrams(sentences):\n",
        "    unigrams = Counter()\n",
        "    bigrams = Counter()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        unigrams.update(sentence)\n",
        "        bigrams.update(ngrammer(sentence))\n",
        "    return (unigrams, bigrams)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7ZTVbhzrcDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(unigrams_text1, bigrams_text1) = ngrams(sentences_text1)\n",
        "(unigrams_text2, bigrams_text2) = ngrams(sentences_text2)\n",
        "(unigrams_text3, bigrams_text3) = ngrams(sentences_text3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSm04buqrcDH",
        "colab_type": "code",
        "outputId": "f80d3d83-6d3f-4003-9fd7-5356ff53446d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(unigrams_text1)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EFiSsLsrcDK",
        "colab_type": "code",
        "outputId": "f661bf6f-f5bb-43da-c850-60009b5edeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(unigrams_text2)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeWuAwqMp0v4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "497d0b11-8b40-4b06-c97b-a8f8a2a1fba1"
      },
      "source": [
        "len(unigrams_text3)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTkJyicarcDM",
        "colab_type": "code",
        "outputId": "2fdd6dea-e3ee-4487-8e4d-9c36d4619fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "bigrams_text1.most_common(10)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> –', 1060),\n",
              " ('– сказал', 165),\n",
              " ('<start> она', 137),\n",
              " ('<start> и', 117),\n",
              " ('степан аркадьич', 115),\n",
              " ('<start> он', 114),\n",
              " ('– сказала', 98),\n",
              " ('– я', 95),\n",
              " ('<start> но', 91),\n",
              " ('что он', 77)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmVzIDP6qAyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1c7a9e67-f5bb-41b1-a7f5-3062ebac4768"
      },
      "source": [
        "bigrams_text2.most_common(10)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> —', 683),\n",
              " ('<start> я', 145),\n",
              " ('степан трофимович', 133),\n",
              " ('<start> он', 99),\n",
              " ('фр <end>', 96),\n",
              " ('<start> но', 91),\n",
              " ('и не', 90),\n",
              " ('варвара петровна', 86),\n",
              " ('что он', 72),\n",
              " ('— я', 66)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBBPuH6EqBF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8dfbcde9-e870-4371-9874-24ecdaf696a8"
      },
      "source": [
        "bigrams_text3.most_common(10)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start> –', 2098),\n",
              " ('– сказал', 413),\n",
              " ('– да', 194),\n",
              " ('<start> в', 174),\n",
              " ('<start> но', 159),\n",
              " ('и не', 155),\n",
              " ('<start> и', 155),\n",
              " ('<start> он', 152),\n",
              " ('– а', 152),\n",
              " ('и в', 150)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7PKs9crcDP",
        "colab_type": "text"
      },
      "source": [
        "Чтобы посчитать условную вероятность мы можем поделить количество вхождений на количество вхождений первого слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w76PP7-srcDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_sent(phrase, bigrams, unigrams):\n",
        "  prob = 0\n",
        "  for ngram in ngrammer(['<start>'] + normalize(phrase) + ['<end>']):\n",
        "    word1, word2 = ngram.split()\n",
        "    if word1 in unigrams and ngram in bigrams:\n",
        "        prob += np.log(bigrams[ngram]/unigrams[word1])\n",
        "    else:\n",
        "        prob += -10\n",
        "  return prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFqko4YtstbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#phrase = 'Нужно быть действительно великим человеком, чтобы суметь устоять даже против здравого смысла.'\n",
        "phrase = 'Все смешалось в доме облонских'\n",
        "probs_sents = Counter(Tolstoy = prob_sent(phrase, bigrams_text1, unigrams_text1), Dostoevsky = prob_sent(phrase, bigrams_text2, unigrams_text2), Gogol = prob_sent(phrase, bigrams_text3, unigrams_text3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1X_byTSrcDU",
        "colab_type": "code",
        "outputId": "c1fb8859-400d-4df4-8064-b7d5aac85db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(prob.most_common())\n",
        "probs_sents.most_common()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('tolstoy', -34.633123830662726), ('gogol', -44.76306777592244), ('dostoevsky', -51.53599792630299)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Tolstoy', -18.91589633142466),\n",
              " ('Gogol', -49.52445391777101),\n",
              " ('Dostoevsky', -50.47792797548535)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvof_6BKrcDW",
        "colab_type": "text"
      },
      "source": [
        "Работает получше. Мы воспользовались небольшим хаком - для слов или биграммов, которых не было у нас в словаре, прибавляли низкую вероятность. Исправить это по-нормальному - сложно, придется подробнее разбираться с вероятностями, сглаживаниями и заменой неизвестных слов. Если интрересно - в книге Журафского про это есть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAllH823rcDX",
        "colab_type": "text"
      },
      "source": [
        "Проблем с неизвестными словами у нас не будет, если мы будем пытаться сгенерировать новый текст. Давайте попробуем это сделать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGfIeaBrcDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a9b963d4-bf34-4b07-8023-aa9b90fa4a33"
      },
      "source": [
        "matrix_text1 = np.zeros((len(unigrams_text1), \n",
        "                   len(unigrams_text1)))\n",
        "id2word_text1 = list(unigrams_text1)\n",
        "word2id_text1 = {word:i for i, word in enumerate(id2word_text1)}\n",
        "\n",
        "counter = 10\n",
        "for ngram in bigrams_text1:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_text1[word2id_text1[word1]][word2id_text1[word2]] =  (bigrams_text1[ngram]/\n",
        "                                                                     unigrams_text1[word1])\n",
        "\n",
        "for i in range(0,len(unigrams_text1)):\n",
        "  for j in range(0,len(unigrams_text1)):\n",
        "    if counter > 0 and matrix_text1[i,j] > 0:\n",
        "      print(matrix_text1[i,j])\n",
        "      counter -= 1"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0003333333333333333\n",
            "0.35333333333333333\n",
            "0.01\n",
            "0.0003333333333333333\n",
            "0.0003333333333333333\n",
            "0.005\n",
            "0.006\n",
            "0.011333333333333334\n",
            "0.0003333333333333333\n",
            "0.001\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuhMAMMJrcDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ab08371-8818-4018-b659-dd37d1e67fda"
      },
      "source": [
        "# создадим матрицу вероятностей перейти из 1 слов в другое\n",
        "matrix_text2 = np.zeros((len(unigrams_text2), \n",
        "                   len(unigrams_text2)))\n",
        "id2word_text2 = list(unigrams_text2)\n",
        "word2id_text2 = {word:i for i, word in enumerate(id2word_text2)}\n",
        "\n",
        "\n",
        "# вероятность расчитываем точно также\n",
        "for ngram in bigrams_text2:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_text2[word2id_text2[word1]][word2id_text2[word2]] =  (bigrams_text2[ngram]/\n",
        "                                                                     unigrams_text2[word1])\n",
        "\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2T62YIgrcDd",
        "colab_type": "text"
      },
      "source": [
        "Для генерации нам понадобится функция np.random.choice , которая выбирает случайный объект из заданных. Ещё в неё можно подать вероятность каждого объекта и она будет доставать по ним (не только максимальный по вероятности)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etSVL_1_4ZUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2258278-145b-4ad5-a77d-0ae70b20634a"
      },
      "source": [
        "mtrx = np.zeros((3,3))\n",
        "mtrx[1] = [0.3, 0.2, 0.5]\n",
        "print(mtrx.shape)\n",
        "print(mtrx[1])\n",
        "count = Counter({1:0, 2:0, 0:0})\n",
        "for i in range (0,20): \n",
        "  count[np.random.choice(mtrx.shape[1], p=mtrx[1])] += 1\n",
        "  \n",
        "print(count.most_common())  "
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3)\n",
            "[0.3 0.2 0.5]\n",
            "[(2, 12), (1, 5), (0, 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nDi-h6mrcDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhPCe0atrcDh",
        "colab_type": "code",
        "outputId": "4883e45c-b37d-46a7-dde9-dfb72823a611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(generate(matrix_text1, id2word_text1, word2id_text1).replace('<end>', '\\n'))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "замер \n",
            " надолго с наслаждением полною грудью она встретила вронского с тобой стараемся поскорее наесться чтобы левин сердито сказал он поднял один из маленькой муфты висевшей на вошедшего и она прошла мимо \n",
            " брата моего ребенка и сердце \n",
            " ты зачем я все в дом стало досадно и всегда и ни к ней для меня поняла зачем ты для левина \n",
            " «а может простить то что ли \n",
            " очень мила \n",
            " – вот возьми на середине мазурки с ног его решительным легким шагом вывернутых ног его мысли \n",
            " как хочешь я иначе \n",
            " на его произведет на вальсировавшую анну \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt62G0kDrcDm",
        "colab_type": "code",
        "outputId": "361d12a2-8b2b-4725-c37f-2b26bdd80bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(generate(matrix_tolstoy, id2word_tolstoy, word2id_tolstoy).replace('<end>', '\\n'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "– сказала вдруг как он считал своим шуточным тоном – проговорил он жадно всматривался \n",
            " vii приехав с тою любовью – я не мог простить \n",
            " она беспрестанно как краснеют мальчики – стало быть заряженные пистолеты \n",
            " – сказала она любила этого дня на тело подошел с развратным отцом и хотят вывести из тех влюблений которые все запиской в дверях двинулась было в то в то что и ступай – писала ей несколько лет с облонским стали такие мускулы да – он собирался сделать – сказал степан аркадьич улыбаясь на него все записываю \n",
            " вронский и вронский выехал из моих\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cASg3mc5rcDq",
        "colab_type": "text"
      },
      "source": [
        "## Коллокации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJyRLRyrcDs",
        "colab_type": "text"
      },
      "source": [
        "Коллокации - это устойчивые выражения, состоящие из двух и более слов. Устойчивые - значит, что они часто используются вместе. Также часто значения коллокации не могут быть выведены лишь из значений, входящих в них слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggxFwPBErcDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [morph.parse(word.strip(punctuation))[0].normal_form for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text\n",
        "\n",
        "\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHdit3LqrcDw",
        "colab_type": "text"
      },
      "source": [
        "Предобработаем почти также, только теперь нам не нужны тэги начала и конца."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GbkL5yPXrcDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_dostoevsky =  [normalize(text) for text in sent_tokenize(dostoevsky)]\n",
        "sentences_tolstoy =  [normalize(text) for text in sent_tokenize(tolstoy)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUyVJd6UrcD0",
        "colab_type": "text"
      },
      "source": [
        "В списке много всяких чисел, однобуквеных слов и стоп-слов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJik6-kfrcD1",
        "colab_type": "text"
      },
      "source": [
        "Добавим какие-нибудь ограничения к коду выше, чтобы биграммы получались почище."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MErGwbzDrcD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cyYWpA-rcD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stops = set(stopwords.words('russian') + ['–'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn7Jqix3rcD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, stops, n=2):\n",
        "    ngrams = []\n",
        "    tokens = [token for token in tokens if token not in stops]\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append('_'.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDiZzddZrcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counter = Counter()\n",
        "\n",
        "for text in sentences_tolstoy:\n",
        "    word_counter.update(ngrammer(text, n=2, stops=stops))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZBwe49TrcEH",
        "colab_type": "code",
        "outputId": "6abafcb1-993c-4665-bb81-b5df2857150c",
        "colab": {}
      },
      "source": [
        "word_counter.most_common(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('алексей_александр', 577),\n",
              " ('степан_аркадьй', 549),\n",
              " ('сергей_иван', 294),\n",
              " ('дарья_александр', 209),\n",
              " ('весь_это', 171),\n",
              " ('сказать_левин', 155),\n",
              " ('сказать_степан', 114),\n",
              " ('лидий_иван', 104),\n",
              " ('сказать_вронский', 88),\n",
              " ('сказать_анна', 88),\n",
              " ('знать_это', 87),\n",
              " ('говорить_это', 86),\n",
              " ('агафья_михайло', 76),\n",
              " ('графиня_лидий', 74),\n",
              " ('сказать_кить', 62)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H89wMkrzrcEO",
        "colab_type": "text"
      },
      "source": [
        "В списке есть коллокации, которые попали в список из-за того, что одно слово очень частотное и вообще встречается много в каких контекстах. Нас скорее интересуют случаи, когда слова в большинстве случаев встречаются вместе. Для этого мы можем придумать какие-нибудь формулы, учитывающие частоты слов по отдельности и общую частоту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bwm5uFJrcEP",
        "colab_type": "text"
      },
      "source": [
        "Самый простой способ - взять количество упоминаний биграма и поделить на сумму количеств упоминаний слов по отдельности. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfvuhpQ0rcEQ",
        "colab_type": "text"
      },
      "source": [
        "Такая формула называется PMI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TRIx5lrcEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scorer_simple(word_count_a, word_count_b, bigram_count, *args):\n",
        "    try:\n",
        "        score = bigram_count/((word_count_a+word_count_b))\n",
        "    \n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrqwlYaPrcEU",
        "colab_type": "text"
      },
      "source": [
        "Сделаем функцию, которая будет делать счетчики для слов и биграммов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnAesZrUrcEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_stats(texts, stops):\n",
        "    ## соберем статистики для отдельных слов\n",
        "    ## и биграммов\n",
        "    \n",
        "    unigrams = Counter()\n",
        "    bigrams = Counter()\n",
        "    \n",
        "    for text in texts:\n",
        "        unigrams.update(text)\n",
        "        bigrams.update(ngrammer(text, stops, 2))\n",
        "    \n",
        "    return unigrams, bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX6FbxHNrcEf",
        "colab_type": "text"
      },
      "source": [
        "И функцию, которая пройдет по всем биграммам и вычислит для них нашу метрику."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeY0xEKxrcEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_bigrams(unigrams, bigrams, scorer, threshold=-100000, min_count=5):\n",
        "    ## посчитаем метрику для каждого нграмма\n",
        "    bigram2score = Counter()\n",
        "    len_vocab = len(unigrams)\n",
        "    for bigram in bigrams:\n",
        "        score = scorer(unigrams[bigram[0]], unigrams[bigram[1]], \n",
        "                       bigrams[bigram], len_vocab, min_count)\n",
        "        \n",
        "        ## если метрика выше порога, добавляем в словарик\n",
        "        if score > threshold:\n",
        "            bigram2score[bigram] = score\n",
        "    \n",
        "    return bigram2score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_eHejBFrcEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams, bigrams = collect_stats(sentences_tolstoy, stops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt_r0G9_rcEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram2score = score_bigrams(unigrams, bigrams, scorer_simple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL2sP40wrcE1",
        "colab_type": "text"
      },
      "source": [
        "Проблема с таким подходом в том, что на самом верху окажутся слова, которые встречают по одному разу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwmsqsTWrcE2",
        "colab_type": "code",
        "outputId": "342f4776-32ce-41d9-8e44-0a57f1b4cb0a",
        "colab": {}
      },
      "source": [
        "bigram2score.most_common(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('человек_который', 61.0),\n",
              " ('знать_это', 43.5),\n",
              " ('первое_время', 32.0),\n",
              " ('это_мочь', 30.5),\n",
              " ('это_весь', 29.0),\n",
              " ('это_дело', 28.5),\n",
              " ('это_время', 26.0),\n",
              " ('графиня_лидий', 24.666666666666668),\n",
              " ('левин_чувствовать', 24.0),\n",
              " ('несмотря_весь', 23.0),\n",
              " ('дело_который', 22.0),\n",
              " ('это_самый', 22.0),\n",
              " ('левин_видеть', 22.0),\n",
              " ('левин_мочь', 19.0),\n",
              " ('левин_понять', 19.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uwnP3LVrcFT",
        "colab_type": "text"
      },
      "source": [
        "Поэтому можно немного переделать оценивающую функцию, добавив минимальное число вхождений для биграмма."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUfmP0oyrcFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scorer(word_count_a, word_count_b, bigram_count, len_vocab, min_count):\n",
        "    try:\n",
        "        score = ((bigram_count - min_count) / ((word_count_a + word_count_b)))\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WTtBOw8rcFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram2score = score_bigrams(unigrams, bigrams, scorer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCtylA7_rcFp",
        "colab_type": "code",
        "outputId": "80d9a421-7bc4-44ce-e359-a7184a58fe8b",
        "colab": {}
      },
      "source": [
        "bigram2score.most_common(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('человек_который', 56.0),\n",
              " ('знать_это', 41.0),\n",
              " ('это_мочь', 28.0),\n",
              " ('первое_время', 27.0),\n",
              " ('это_весь', 26.5),\n",
              " ('это_дело', 26.0),\n",
              " ('это_время', 23.5),\n",
              " ('графиня_лидий', 23.0),\n",
              " ('это_самый', 19.5),\n",
              " ('левин_чувствовать', 19.0),\n",
              " ('несмотря_весь', 18.0),\n",
              " ('дело_который', 17.0),\n",
              " ('левин_видеть', 17.0),\n",
              " ('это_сказать', 16.0),\n",
              " ('друг_друг', 15.333333333333334)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-rRYPBrcFt",
        "colab_type": "text"
      },
      "source": [
        "В статье про Word2Vec для создания нграммов использовалась такая функция:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdOLofFrcFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scorer_w2v(word_count_a, word_count_b, bigram_count, len_vocab, min_count=10):\n",
        "\n",
        "    try:\n",
        "        score = ((bigram_count - min_count) / (word_count_a * word_count_b)) * len_vocab\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayZN1NtErcFz",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, отличается ли она от нашей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjV1tc5MrcF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram2score = score_bigrams(unigrams, bigrams, scorer_w2v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F48mzg1yrcF4",
        "colab_type": "code",
        "outputId": "27cc9ce3-fb7e-4db9-fd9c-3f55aef1bf16",
        "colab": {}
      },
      "source": [
        "bigram2score.most_common(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ребёнок_который', 34925.333333333336),\n",
              " ('решить_ехать', 14968.0),\n",
              " ('редко_бывать', 14968.0),\n",
              " ('решить_это', 9978.666666666666),\n",
              " ('решительно_знать', 9978.666666666666),\n",
              " ('ребёнок_мочь', 4989.333333333333),\n",
              " ('решительно_понимать', 4989.333333333333),\n",
              " ('mademoiselle_linon', 2494.6666666666665),\n",
              " ('железный_дорога', 2204.589147286822),\n",
              " ('женщина_который', 2204.589147286822),\n",
              " ('желать_это', 1624.4341085271317),\n",
              " ('сергей_иван', 1198.2692520775622),\n",
              " ('жена_посланник', 1160.3100775193798),\n",
              " ('брат_николай', 1116.0350877192982),\n",
              " ('женщина_это', 464.1240310077519)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUgBr8jorcF-",
        "colab_type": "text"
      },
      "source": [
        "Во всех случаях выше мы считали нграммами только слова, которые встречаются друг за другом. Но в нграммы часто можно ещё что-то вставить. Например, \"принять участие\" может превратиться в \"принять самое активное/непосредственное участие\". \n",
        "\n",
        "Чтобы отловить такие случаи можно считать нграммами слова, которые встречаются внутри какого-то окна. И считать по ним все те же метрики."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSjXAXXgrcF_",
        "colab_type": "text"
      },
      "source": [
        "Можно ещё посчитать стандартное отклонение расстояния между двумя словами. Если оно маленькое - слова обычно стоят на строгой позиции по отношению друг к другу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3968MIercGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "def get_window_stats(texts, window=8):\n",
        "    \n",
        "    bigrams = defaultdict(list)\n",
        "    \n",
        "    # проходим окном по текстам \n",
        "    # берем первое слово и считаем его целевым\n",
        "    # проходим по остальным словам и их индексам\n",
        "    # добавляем в словарь пары (целевое слов, текущее слово)\n",
        "    # и добавляем индекс текущего в список этой пары\n",
        "    # так мы получаем (слово_1,слово_2):[1,2,1,1,3,2]\n",
        "    # порядок в этом случае учитывается - (слово_2, слово_1) - другая запись\n",
        "    for text in texts:\n",
        "        for i in range(len(text)-window):\n",
        "            words = list(enumerate(text[i:i+window]))\n",
        "            target = words[0][1]\n",
        "            for j, word in words[1:]:\n",
        "                bigrams[(target, word)].append(j)\n",
        "    \n",
        "    bigrams_stds = Counter()\n",
        "    for bigram in bigrams:\n",
        "        # выкидываем биграмы встретившиеся < 5 раз\n",
        "        if len(bigrams[bigram]) > 5:\n",
        "            bigrams_stds[bigram] = np.std(bigrams[bigram])\n",
        "    \n",
        "    return bigrams_stds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrFUFS72rcGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram2std = get_window_stats(sentences_dostoevsky)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw5x8TNdrcGI",
        "colab_type": "code",
        "outputId": "08bc979c-c458-4cc0-f06c-a2c25a73dc52",
        "colab": {}
      },
      "source": [
        "bigram2std.most_common()[:-20:-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('софья', 'матвей'), 0.0),\n",
              " (('большой', 'дорога'), 0.0),\n",
              " (('ваш', 'превосходительство'), 0.0),\n",
              " (('знаешь', 'ли'), 0.0),\n",
              " (('общий', 'дело'), 0.0),\n",
              " (('арин', 'прохор'), 0.0),\n",
              " (('вслед', 'за'), 0.0),\n",
              " (('семён', 'яков'), 0.0),\n",
              " (('воротиться', 'домой'), 0.0),\n",
              " (('из', 'сила'), 0.0),\n",
              " (('cher', 'он'), 0.0),\n",
              " (('алексей', 'егор'), 0.0),\n",
              " (('господин', 'кармазин'), 0.0),\n",
              " (('чуть', 'ли'), 0.0),\n",
              " (('артемий', 'павло'), 0.0),\n",
              " (('замечать', 'что'), 0.0),\n",
              " (('какой-то', 'особенный'), 0.0),\n",
              " (('с', 'постель'), 0.0),\n",
              " (('ради', 'бог'), 0.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE7zrbwircGP",
        "colab_type": "text"
      },
      "source": [
        "Можно применять расширить размер нграмма, а можно последовательно преобразовывать один и тот же текст, на каждом шагу собирая новые биграммы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgSSayMPrcGS",
        "colab_type": "text"
      },
      "source": [
        "Напишием такую функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkDEW7kMrcGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bigram_text(text, bigram2score):\n",
        "    new_text = []\n",
        "    i = 0\n",
        "    \n",
        "    while i < (len(text)-1):\n",
        "        bigram = '_'.join((text[i], text[i+1]))\n",
        "        if bigram in bigram2score:\n",
        "            new_text.append(bigram)\n",
        "            i += 2\n",
        "        else:\n",
        "            new_text.append(text[i])\n",
        "            i += 1\n",
        "    else:\n",
        "        if i == (len(text)-1):\n",
        "            new_text.append(text[i])\n",
        "    \n",
        "    return new_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55V6-eLkrcGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams, bigrams = collect_stats(sentences_dostoevsky, stops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDlQjvGIrcGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram2score = score_bigrams(unigrams, bigrams, scorer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZxDBo8xrcGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_dostoevsky_2 = [bigram_text(sent, bigram2score) for sent in sentences_dostoevsky]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xANqlpDBrcG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams, bigrams = collect_stats(sentences_dostoevsky_2, stops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raHIoFpdrcHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigram2score = score_bigrams(unigrams, bigrams, scorer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gGG2B0crcHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_dostoevsky_3 = [bigram_text(sent, trigram2score) for sent in sentences_dostoevsky_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et3f_5BrrcHI",
        "colab_type": "code",
        "outputId": "93a09133-c8ee-488c-b46c-c8ca4963f5b9",
        "colab": {}
      },
      "source": [
        "sentences_dostoevsky_3[4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['домовый', 'ли', 'хоронить_ведьма_ль_замуж', 'выдавать']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WSCb-CrcHY",
        "colab_type": "text"
      },
      "source": [
        "По этой ссылке можно прочитать про другие метрики.\n",
        "\n",
        "http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S1405-55462016000300327#t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SExdEzParcHZ",
        "colab_type": "text"
      },
      "source": [
        "### Все готовое"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1nzkGxIrcHa",
        "colab_type": "text"
      },
      "source": [
        "Писать все это самому конечно не обязательно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in1AOryhrcHc",
        "colab_type": "text"
      },
      "source": [
        "Удобно пользоваться phraser из gensim'а. Он собирает статистику по корпусу, а затем склеивает слова в биграммы. Так как мы сделали выше. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTMb7u2ZrcHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfrqae51rcH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# собираем статистики\n",
        "ph = gensim.models.Phrases(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFX-9pymrcH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# преобразовывать можно и через ph, но так быстрее \n",
        "p = gensim.models.phrases.Phraser(ph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfhD90FprcH9",
        "colab_type": "text"
      },
      "source": [
        "По умолчанию там используется метрики из статьи про ворд2век и ещё есть нормализованные pmi.\n",
        "Если не нравятся функции оценки, то ему можно подать любую другую функцию. Интерфейс у функции там почти точно такой же как и у наших."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsuJl4ZArcH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UFBtqTkrcIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# собираем статистики по уже забиграммленному тексту\n",
        "ph2 = gensim.models.Phrases(p[texts])\n",
        "p2 = gensim.models.phrases.Phraser(ph2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEcBHuwKrcIK",
        "colab_type": "code",
        "outputId": "c6590379-1c47-4b1b-9ec2-919a93c3f6f5",
        "colab": {}
      },
      "source": [
        "p2[p[texts[0]]][:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['многие',\n",
              " 'интересоваться',\n",
              " 'зачем',\n",
              " 'нужный',\n",
              " '«яблоку»',\n",
              " 'молодёжный',\n",
              " 'фракция',\n",
              " 'основной_задача',\n",
              " '«молодёжный',\n",
              " '«яблока»',\n",
              " 'являться',\n",
              " 'привлечение',\n",
              " 'молодая_человек',\n",
              " 'к',\n",
              " 'участие',\n",
              " 'в',\n",
              " 'выборы',\n",
              " 'и',\n",
              " 'деятельность',\n",
              " 'партия']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekiVJQthrcIZ",
        "colab_type": "text"
      },
      "source": [
        "Ну и наконец нграммы есть в нлтк. Тут больше метрик, но преборазователь слов в нграммы нужно написать самому."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNgKD8M9rcIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.collocations import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMDDgLAurcIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ivn1ITZrcIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finder2 = BigramCollocationFinder.from_documents(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbyBaASBrcI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finder3 = TrigramCollocationFinder.from_documents(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pPTUA4rErcI6",
        "colab_type": "code",
        "outputId": "558f555e-e460-43b7-90d3-e91338a85209",
        "colab": {}
      },
      "source": [
        "finder2.nbest(bigram_measures.likelihood_ratio, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('один', 'из'),\n",
              " ('тот', 'что'),\n",
              " ('а', 'также'),\n",
              " ('при', 'это'),\n",
              " ('2017', 'год'),\n",
              " ('не', 'только'),\n",
              " ('точка', 'зрение'),\n",
              " ('то', 'есть'),\n",
              " ('сей', 'пора'),\n",
              " ('тот', 'число'),\n",
              " ('куб', 'метр'),\n",
              " ('владимир', 'путин'),\n",
              " ('2016', 'год'),\n",
              " ('тот', 'же'),\n",
              " ('потому', 'что'),\n",
              " ('миллиард', 'доллар'),\n",
              " ('о', 'тот'),\n",
              " ('прежде', 'всего'),\n",
              " ('кроме', 'тот'),\n",
              " ('до', 'сей')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dS3U1-IJrcJI",
        "colab_type": "code",
        "outputId": "76f2cb9c-e227-4350-dd13-c2284da4ef49",
        "colab": {}
      },
      "source": [
        "finder3.nbest(trigram_measures.pmi, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1947–2001»', 'monterey', 'ca'),\n",
              " ('50-летие', 'rolling', 'stones'),\n",
              " ('acs', 'nano', 'letters'),\n",
              " ('areva', 'edf', 'alstom'),\n",
              " ('armored', 'multi-purpose', 'vehicles'),\n",
              " ('atr', 'ленур', 'ислям'),\n",
              " ('bad', 'can', 'it'),\n",
              " ('bourgeois', '«эпатировать', 'буржуа»'),\n",
              " ('bundesanstalt', 'fuer', 'geowissenschaften'),\n",
              " ('can', 'it', 'be'),\n",
              " ('charge', 'ion', 'battery'),\n",
              " ('citizens', '1947–2001»', 'monterey'),\n",
              " ('commitment', 'competence', 'consensus'),\n",
              " ('corriere', 'della', 'sera'),\n",
              " ('della', 'sera', 'папа-на-покой'),\n",
              " ('diyanet', 'isleri', 'turk-islam'),\n",
              " ('dux', 'recording', 'producers'),\n",
              " ('edf', 'alstom', 'schneider'),\n",
              " ('egf', 'gazprom', 'monitor'),\n",
              " ('espanola', 'чть', 'прад')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaKbhQMurcJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}